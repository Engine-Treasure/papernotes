# Table of contents

* [PaperHighlights](README.md)
* [2018](2018/README.md)
  * [5](2018/5/README.md)
    * [Text Understanding with the Attention Sum Reader Network](2018/5/text_understanding_with_asreader.md)
    * [Effective Approaches to Attention-based Neural Machine Translation](2018/5/effective_approaches_to_attention-based_nmt.md)
    * [Distance-based Self-Attention Network for Natural Language Inference](2018/5/distance-based_self-attention_network_for_nli.md)
    * [Deep Residual Learning for Image Recognition](2018/5/resnet.md)
    * [U-Net: Convolutional Networks for Biomedical Image Segmentation](2018/5/u-net.md)
    * [Memory Networks](2018/5/memory_networks.md)
    * [Neural Machine Translation by Jointly Learning to Align and Translate](2018/5/nmt-by-jointly-learning-to-align-and-translate.md)
    * [Convolutional Sequence to Sequence Learning](2018/5/convs2s.md)
    * [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](2018/5/tcn.md)
    * [Graph Attention Networks](2018/5/graph_attention_networks.md)
    * [Attention is All You Need](2018/5/attn-is-all-you-need.md)
    * [DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding](2018/5/disan.md)
    * [A Structured Self-attentive Sentence Embedding](2018/5/a_structured_self_attentive_sentence_embedding.md)
    * [Hierarchical Attention Networks for Document Classification](2018/5/hierarchical_attn_net_for_document_classification.md)
    * [Grammar as a Foreign Language](2018/5/grammar_as_a_foreign_language.md)
    * [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](2018/5/show_attent_and_tell.md)
    * [Transforming Auto-encoders](2018/5/transforming_auto-encoders.md)
    * [Self-Attention with Relative Position Representations](2018/5/self-attention_with_relative_position_representations.md)
  * [6](2018/6/README.md)
    * [Universal Language Model Fine-tuning for Text Classification](2018/6/ulmfit.md)
    * [Semi-supervised sequence tagging with bidirectional language models](2018/6/semi-supervised_seq_tagging_with_bilm.md)
    * [Consensus Attention-based Neural Networks for Chinese Reading Comprehension](2018/6/casreader.md)
    * [Attention-over-Attention Neural Networks for Reading Comprehension](2018/6/aoa_reader.md)
    * [Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms](2018/6/swem.md)
    * [Convolutional Neural Networks for Sentence Classification](2018/6/cnn_for_sentence_classification.md)
    * [Deep contextualized word representations](2018/6/elmo.md)
    * [Neural Architectures for Named Entity Recognition](2018/6/neural_architectures_for_ner.md)
    * [Improving Language Understanding by Generative Pre-Training](2018/6/improving_language_understanding_by_generative_pre-training.md)
    * [A Sensitivity Analysis of \(and Practitioners’ Guide to\) Convolutional Neural Networks for Sentence C](2018/6/a_sensitivity_analysis_of_cnn4sc.md)
    * [Teaching Machines to Read and Comprehend](2018/6/teaching_machines_to_read_and_comprehend.md)
  * [11](2018/11/README.md)
    * [Think Globally, Embed Locally — Locally Linear Meta-embedding of Words](2018/11/think_globally_embed_locally.md)
    * [Learning linear transformations between counting-based and prediction-based word embeddings](2018/11/learning_linear_transformations_between_counting-based_and_prediction-based_we.md)
    * [Learning Word Meta-Embeddings by Autoencoding](2018/11/learning_word_meta-embedding_by_autoencoding.md)
    * [Learning Word Meta-Embeddings](2018/11/learning_word_meta-embeddings.md)
    * [Frustratingly Easy Meta-Embedding – Computing Meta-Embeddings by Averaging Source Word Embeddings](2018/11/wme_av.md)
  * [1](2018/1/README.md)
    * [20180108-20180114](2018/1/1.md)
* [2019](2019/README.md)
  * [03](2019/03/README.md)
    * [Not All Contexts Are Created Equal Better Word Representations with Variable Attention](2019/03/not_all_contexts_are_created_equal.md)
    * [Learning Context-Sensitive Word Embeddings with Neural Tensor Skip-Gram Model](2019/03/learning_context-sensitive_word_embeddings_with_neural_tensor_skip-gram_model.md)
    * [Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet](2019/03/approximating_cnns_with_bag_of_local_features_models_works_supprisingly_well_on_imagenet.md)
    * [pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference](2019/03/pair2vec.md)
    * [Contextual Word Representations: A Contextual Introduction](2019/03/contextual_word_representations.md)
    * [Not All Neural Embeddings are Born Equal](2019/03/not_all_neural_embeddings_are_born_equal.md)
    * [High-risk learning: acquiring new word vectors from tiny data](2019/03/high-risk_learning_acquiring_new_word_vectors_from_tiny_data.md)
    * [Learning word embeddings from dictionary definitions only](2019/03/learning_word_embeddings_from_dictionary_definitions_only.md)
    * [Dependency-Based Word Embeddings](2019/03/dependency-based_word_embeddings.md)
  * [01](2019/01/README.md)
    * [Querying Word Embeddings for Similarity and Relatedness](2019/01/querying_word_embeddings_for_similarity_and_relatedness.md)
    * [Data Distillation: Towards Omni-Supervised Learning](2019/01/data_distillation.md)
    * [A Rank-Based Similarity Metric for Word Embeddings](2019/01/a_rank-based_similarity_metric_for_word_embeddings.md)
    * [Dict2vec: Learning Word Embeddings using Lexical Dictionaries](2019/01/dict2vec.md)
    * [Graph Convolutional Networks for Text Classification](2019/01/graph_convolutional_networks_for_text_classification.md)
    * [Improving Distributional Similarity with Lessons Learned from Word Embeddings](2019/01/improving_distributional_similarity_with_lessons_learned_from_word_embeddings.md)
    * [Real-time Personalization using Embeddings for Search Ranking at Airbnb](2019/01/real-time_personalization_using_embeddings_for_search_ranking_at_airbnb.md)
    * [Glyce: Glyph-vectors for Chinese Character Representations](2019/01/glyce.md)
    * [Auto-Encoding Dictionary Definitions into Consistent Word Embeddings](2019/01/auto-encoding_dictionary_definitions_into_consistent_word_embeddings.md)
    * [Distilling the Knowledge in a Neural Network](2019/01/distilling_the_knowledge_in_a_nn.md)
    * [Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrin](2019/01/uncovering_divergent_linguistic_information_in_word_embeddings_with_lessons_for_intrinsic_and_extrin.md)
    * [The \(Too Many\) Problems of Analogical Reasoning with Word Vectors](2019/01/problems_of_analogical_reasoning_with_word_vectors.md)
    * [Linear Ensembles of Word Embedding Models](2019/01/linear_ensembles_of_word_embedding_models.md)
    * [Intrinsic Evaluation of Word Vectors Fails to Predict Extrinsic Performance](2019/01/intrinsic_evaluation_of_word_vectors_fails_to_predict_extrinsic_performance.md)
    * [Dynamic Meta-Embeddings for Improved Sentence Representations](2019/01/dynamic_meta-embeddings_for_improved_sentence_representations.md)
  * [02](2019/02/README.md)
    * [Improving Word Embedding Compositionality using Lexicographic Definitions](2019/02/improving_word_embedding_compositionality_using_lexicographic_definitions.md)
    * [From Word Embeddings To Document Distances](2019/02/from_word_embeddings_to_document_distances.md)
    * [Progressive Growing of GANs for Improved Quality, Stability, and Variation](2019/02/progressive_gan.md)
    * [Retrofitting Word Vectors to Semantic Lexicons](2019/02/retrofitting_word_vectors_to_semantic_lexicons.md)
    * [Bag of Tricks for Image Classification with Convolutional Neural Networks](2019/02/bag_of_tricks_for_image_classification_with_cnn.md)
    * [Multi-Task Deep Neural Networks for Natural Language Understanding](2019/02/multi-task_deep_neural_networks_for_natural_language_understanding.md)
    * [Snapshot Ensembles: Train 1, get M for free](2019/02/snapshot_ensembles.md)
    * [EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks](2019/02/easy_data_augmentation_techniques_for_performace_on_text_classification_tasks.md)
    * [Counter-fitting Word Vectors to Linguistic Constraints](2019/02/counter-fitting_word_vectors_to_linguistic_constraints.md)
    * [AdaScale: Towards Real-time Video Object Detection Using Adaptive Scaling](2019/02/adascale.md)
    * [Learning semantic similarity in a continuous space](2019/02/learning_semantic_similarity_in_a_continuous_space.md)
    * [Progressive Neural Networks](2019/02/progressive_neural_networks.md)
    * [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](2019/02/bert.md)
    * [Language Models are Unsupervised Multitask Learners](2019/02/language_models_are_unsupervised_multitask_learners.md)
* [2017](2017/README.md)
  * [11](2017/11/README.md)
    * [20171127-20171203 论文笔记 1](2017/11/48_1.md)
    * [20171106-20171126 论文笔记](2017/11/45_1.md)
    * [20171030-20171105 论文笔记 1](2017/11/44_1.md)
  * [12](2017/12/README.md)
    * [20171218-2017124 论文笔记](2017/12/1.md)
* [Title](template.md)

